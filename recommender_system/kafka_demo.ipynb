{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init('/Users/hyunseokjung/spark-3.3.0')\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10-assembly_2.12-3.3.1 pyspark-shell'\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "n_secs = 1\n",
    "topic = 'pyspark-kafka-demo'\n",
    "\n",
    "conf = SparkConf().setAppName('KafkaStreamProcessor').setMaster('local[*]')\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel('WARN')\n",
    "ssc = StreamingContext(sc, n_secs)\n",
    "\n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id':'video-group',\n",
    "    'fetch.message.max.bytes':'15728640',\n",
    "    'auto.offset.reset':'largest'\n",
    "})\n",
    "\n",
    "lines = kafkaStream.map(lambda x: x[1])\n",
    "counts = lines.flatMap(lambda line: line.split(' ')).map(lambda word: (word, 1)).reduceByKey(lambda a, b : a+b)\n",
    "counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(600)\n",
    "ssc.stop(stopSparkContext=True, stopGraceFully=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbc2b592ccd6079e95c9c6b0edf643b0189dd6a289bfe01be45caefb75409e7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
