{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처 테스트 : https://towardsdatascience.com/build-recommendation-system-with-pyspark-using-alternating-least-squares-als-matrix-factorisation-ebe1ad2e7679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('recommender_system1') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "base_path = '/Users/hyunseokjung/data/movie_dataset/'\n",
    "\n",
    "ratings = spark.read.csv(base_path+'ratings.csv', header=True, inferSchema=True)\n",
    "movies = spark.read.csv(base_path+'movies_metadata.csv', header=True, inferSchema=True)\n",
    "links = spark.read.csv(base_path+'links.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|    110|   1.0|\n",
      "|     1|    147|   4.5|\n",
      "|     1|    858|   5.0|\n",
      "|     1|   1221|   5.0|\n",
      "|     1|   1246|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings = ratings.select('userId', 'movieId', 'rating').cache()\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+\n",
      "|  imdb_id|               title|        vote_average|        release_date|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "|tt0114709|           Toy Story|                 7.7|          1995-10-30|\n",
      "|tt0113497|             Jumanji|                 6.9|          1995-12-15|\n",
      "|tt0113228|    Grumpier Old Men|                 6.5|          1995-12-22|\n",
      "|tt0114885|[{'iso_639_1': 'e...|Friends are the p...|/16XOMpEaLWkrcPqS...|\n",
      "|tt0113041|Father of the Bri...|                 5.7|          1995-02-10|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/06 00:26:18 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1004933 ms exceeds timeout 120000 ms\n",
      "22/12/06 00:26:18 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "movies = movies.select('imdb_id', 'title', 'vote_average', 'release_date').cache()\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([.7, .3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Test) = 0.7244259116516412\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "als = ALS(\n",
    "    rank=30,\n",
    "    maxIter=4,\n",
    "    regParam=0.1,\n",
    "    userCol='userId',\n",
    "    itemCol='movieId',\n",
    "    ratingCol='rating',\n",
    "    coldStartStrategy='drop',\n",
    "    implicitPrefs=False\n",
    ")\n",
    "model = als.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='mae', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(f'MAE (Test) = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:====================================>                 (68 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|userId|    recommendations|\n",
      "+------+-------------------+\n",
      "|     1| [{1950, 3.501675}]|\n",
      "|     2|[{83411, 5.050743}]|\n",
      "|     3|[{1361, 4.4313684}]|\n",
      "|     4| [{1948, 5.595908}]|\n",
      "|     5| [{4357, 4.872115}]|\n",
      "+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.recommendForAllUsers(1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:===========================================>          (81 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieId|   recommendations|\n",
      "+-------+------------------+\n",
      "|     12|[{113, 4.4283714}]|\n",
      "|     26| [{113, 5.159644}]|\n",
      "|     27| [{113, 4.378224}]|\n",
      "|     28|[{464, 4.9823256}]|\n",
      "|     31| [{113, 4.782653}]|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.recommendForAllItems(1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Movie on metadata\n",
    "def get_movie_metadata(movieId):\n",
    "    metadata['imdb_id'] = metadata['imdb_id'].astype('category')\n",
    "    imdb_id = links[links['movieId'] == movieId]\n",
    "    imdb_id = imdb_id.imdbId.values[0]\n",
    "    if len(str(imdb_id)) == 7:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 6:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt0'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 5:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt00'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 4:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt000'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 3:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt0000'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 2:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt00000'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    elif len(str(imdb_id)) == 1:\n",
    "        movie_rated = metadata[metadata['imdb_id'] == 'tt000000'+imdb_id.astype(str)]\n",
    "        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n",
    "        return df.reset_index(drop=True)\n",
    "    else:\n",
    "        pass\n",
    "# Get Movie List\n",
    "def get_movie(df):\n",
    "    movieIdIdx = df['movieId'].values.astype(int)\n",
    "    df_aux_b = pd.DataFrame({'title': ['aaa'], \n",
    "                           'overview': ['bbb'], \n",
    "                           'vote_average': [1.7], \n",
    "                           'release_date': ['1999-01-01']\n",
    "        })\n",
    "    for i in movieIdIdx:\n",
    "        df_aux_b = df_aux_b.append(get_movie_metadata(i), ignore_index=True)\n",
    "\n",
    "    df_aux_b.drop(0, inplace=True)\n",
    "    df_aux_b['release_date'] = df_aux_b['release_date'].apply(lambda x : x.split('-')[0])\n",
    "    df_aux_b['release_date'] = df_aux_b['release_date'].astype(int)\n",
    "    df_aux_b.rename(columns={'release_date' : 'release_year'}, inplace=True)\n",
    "    return df_aux_b.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dracula: Dead and Loving It</td>\n",
       "      <td>When a lawyer shows up at the vampire's doorst...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1995-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0  Dracula: Dead and Loving It   \n",
       "\n",
       "                                            overview  vote_average  \\\n",
       "0  When a lawyer shows up at the vampire's doorst...           5.7   \n",
       "\n",
       "  release_date  \n",
       "0   1995-12-22  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_metadata(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbc2b592ccd6079e95c9c6b0edf643b0189dd6a289bfe01be45caefb75409e7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
